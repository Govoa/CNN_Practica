{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Rescaling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "# La foto es 128x96\n",
    "xpixel = 224\n",
    "ypixel = 224\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 64\n",
    "n_neuronas_conv2 = 128\n",
    "n_neuronas_conv3 = 256\n",
    "l_rate = 0.00001 # empezar en 0.001 e ir bajando para el estudio\n",
    "epoch = 15 \n",
    "batch = 16 # Realmente en 1 esta bien esto es mas para tiempos de ejecucion con grandes cantidades de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto coge los datos originales y los divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meterdatos(batch):\n",
    "    image_size = (xpixel, ypixel)\n",
    "    batch_size = batch\n",
    "\n",
    "    train_generator_t = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=r'../Dataset/imgs/train/',\n",
    "        label_mode = 'categorical',\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        shuffle = True,\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    train_generator_v = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=r'../Dataset/imgs/train/',\n",
    "        label_mode = 'categorical',\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        shuffle = True,\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_generator_t , train_generator_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation no esta implentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meterdatosaug():\n",
    "        train_datagen = ImageDataGenerator( #Aqui se hacen los cambios a las imagenes\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                validation_split = 0.2\n",
    "                )\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                directory=r'../Dataset/imgs/train/',\n",
    "                target_size=(xpixel, ypixel),\n",
    "                batch_size=batch,\n",
    "                class_mode='categorical')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "                directory=r'../Dataset/imgs/train/',\n",
    "                target_size=(xpixel, ypixel),\n",
    "                batch_size=batch,\n",
    "                class_mode='categorical')\n",
    "        return train_generator , validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pintar imagenes dado un tf.keras.preprocessing.image_dataset_from_directory tambien saca el vector de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarimg(t):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in t.take(1):\n",
    "        for i in range(batch):\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            print(labels[i])\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 2 - BUENA DE MOMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_2(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Rescaling(1./255 , input_shape=(x, y, 3))) # Como no he rescalado nada usamos esta capa para normalizar los datos\n",
    "   \n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size=(3,3),padding='same',activation='relu')) \n",
    "    # Capas convolucionales\n",
    "    model.add(MaxPooling2D()) \n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    # (3,3) es mucho se recomienda unsar 1x1 cuando las img no son mayores de 128x128 la nuestra es 128x96\n",
    "    model.add(Conv2D(n_conv2,(3,3),activation='relu',padding='same'))\n",
    "    #model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(MaxPooling2D()) \n",
    "   # model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same'))                                       #model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same'))   \n",
    "    model.add(MaxPooling2D())\n",
    "    #model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected - MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu')) # red fully-connected\n",
    "    model.add(Dense(64,activation='relu')) # red fully-connected\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    # Compilamos\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 3 - PROBAR\n",
    "\n",
    "https://github.com/fomorians/distracted-drivers-keras/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_3(x,y,lr): ###NOOOOO ENTREGAAAAAR CON ESTOOOOOOOOOOOO\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Rescaling(1./255))\n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(x, y, 3)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                        activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                        activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(2048, activation='relu'))\n",
    "        model.add(Dropout(0.5))  # drop 50% of neurons\n",
    "        model.add(Dense(num_clases,activation='softmax'))\n",
    "\n",
    "        # Compilamos\n",
    "        adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "        # output layer: classify to 10 driver's states\n",
    "        \n",
    "        return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar(m,e,v,epo,b):\n",
    "        # Para parar segun el criterio de la pr\n",
    "        elcallback = tf.keras.callbacks.EarlyStopping(\n",
    "          monitor=\"val_loss\",\n",
    "          min_delta=0.2,\n",
    "          patience=2,\n",
    "          verbose=0,\n",
    "          mode=\"min\",\n",
    "          baseline=None,\n",
    "          restore_best_weights=False,\n",
    "        )\n",
    "        #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(\n",
    "        e,\n",
    "        validation_data=v,\n",
    "        epochs= epo,\n",
    "        batch_size = b, \n",
    "        verbose=1, #Esto te imprime un progress bar con informacion \n",
    "        shuffle=True,\n",
    "        callbacks = elcallback     \n",
    "        ) \n",
    "        return m\n",
    "# DATO CURIOSO, .FIT() TIENE UNA OPCION LLAMADA VALIDATION_DATA=, IGUAL NI ES NECESARIO CREAR UN GRUPO DE VALIDACION A PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinta modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarmodelo(modelo):\n",
    "    tf.keras.utils.plot_model(\n",
    "        modelo,\n",
    "        to_file='model.png',\n",
    "        show_shapes=False,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir='TB',\n",
    "        expand_nested=False,\n",
    "        dpi=96,\n",
    "        layer_range=None,\n",
    "        show_layer_activations=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarmodelo():\n",
    "    model = ker.models.load_model('path/to/location') # Carga modelos\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardarmodelo():\n",
    "    model.save('ModeloGuardado') # guarda el modelo en la ruta que desees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campo de Maniobras (Esto seria como el main o algo asi jejejee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 files belonging to 10 classes.\n",
      "Using 17940 files for training.\n",
      "Found 22424 files belonging to 10 classes.\n",
      "Using 4484 files for validation.\n"
     ]
    }
   ],
   "source": [
    "t,v = meterdatos(batch)\n",
    "model = Modelar_red_2(16,32,64,xpixel,ypixel,l_rate) #Puedes cambiar la funcion para elegir otro modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para separar outputs de consola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1122/1122 [==============================] - 35s 30ms/step - loss: 1.7455 - accuracy: 0.4561 - val_loss: 0.9587 - val_accuracy: 0.7634\n",
      "Epoch 2/15\n",
      "  62/1122 [>.............................] - ETA: 27s - loss: 0.9890 - accuracy: 0.7369"
     ]
    }
   ],
   "source": [
    "model = Entrenar(model,t,v,epoch,batch) # si no satisface al callback esto parara "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
