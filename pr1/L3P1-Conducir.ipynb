{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output # Limpiar output\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000005?line=16'>17</a>\u001b[0m img_nombres \u001b[39m=\u001b[39m img_ruta\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000005?line=17'>18</a>\u001b[0m \u001b[39m# img_nombre\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000005?line=18'>19</a>\u001b[0m img_pixeles \u001b[39m=\u001b[39m asarray(img) \u001b[39m/\u001b[39;49m \u001b[39m255\u001b[39;49m \u001b[39m# Pasamos a array y normalizamos \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000005?line=19'>20</a>\u001b[0m entradas_entrenamiento\u001b[39m.\u001b[39mappend(img_pixeles)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000005?line=20'>21</a>\u001b[0m salidas_entrenamiento\u001b[39m.\u001b[39mappend(img_nombres)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Primer paso es convertir las imagenes en un array y etiquetarlas.\n",
    "    Primero de todo, en el siguiente bucle recorreremos todos los ficheros de entrenamiento, convirtiendo cada imagen en una matriz (normalizada / 255)\n",
    "    Una vez la tenemos normalizada, la añadimos al conjunto de entrenamiento\n",
    "    Como cada imagen esta ya en una carpeta según su clase, guardamos de que carpeta pertenece la imagen y así la etiquetamos en las salidas esperadas\n",
    "\"\"\"\n",
    "\n",
    "entradas_entrenamiento = []\n",
    "salidas_entrenamiento = []\n",
    "with os.scandir('../Dataset/imgs/train') as ficheros: # Iteramos todo el conjunto de entrenamiento\n",
    "    for fichero in ficheros:\n",
    "        path = os.path.join(fichero)\n",
    "        tipo_clase = path.split(\"/\")\n",
    "        clase_img = tipo_clase[4]\n",
    "        print(\"Leyendo imágenes de la carpeta \",clase_img,end=\"\\r\")\n",
    "        with os.scandir(path) as imagenes:\n",
    "            for imagen in imagenes:\n",
    "                img_ruta = os.path.join(imagen)\n",
    "                img = Image.open(img_ruta)\n",
    "                img_pixeles = asarray(img) \n",
    "                img_normalizada = img_pixeles / 255 # Normalizamos\n",
    "                entradas_entrenamiento.append(img_normalizada)\n",
    "                salidas_entrenamiento.append(clase_img)\n",
    "print(\"Todas las imágenes del entrenamiento leidas y guardadas\")\n",
    "\n",
    "# Ahora hacemos shuffle y dividimos en entreno y validacion\n",
    "\n",
    "# Shuffle de ambos a la vez para que las posiciones concuerden con las salidas\n",
    "shuffle = list(zip(entradas_entrenamiento, salidas_entrenamiento))\n",
    "random.shuffle(shuffle)\n",
    "entradas_entrenamiento, salidas_entrenamiento = zip(*shuffle)\n",
    "\n",
    "# División\n",
    "entrenamiento_entradas, validacion_entradas = train_test_split(entradas_entrenamiento, test_size = 0.20, shuffle=False)\n",
    "entrenamiento_salidas, validacion_salidas = train_test_split(salidas_entrenamiento, test_size = 0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "xpixel = 128\n",
    "ypixel = 96\n",
    "\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 32\n",
    "n_neuronas_conv2 = 32\n",
    "n_neuronas_conv3 = 32\n",
    "l_rate = 0.1\n",
    "epoch = 12 \n",
    "batch = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero realizamos la aumentación y creación de nuevos imputs a partir de las imagenes que tenemos (Augmentation)\n",
    "Lo realizamos con ImageDataGenerator de keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation(e_entradas,e_salidas,v_entradas,v_salidas,x,y):\n",
    "    train_generator = ImageDataGenerator( # Esto lo vamos a tener que poner todo seguido sin comentar para que no salga plagio !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        rescale=1/255.,              # normalize pixel values between 0-1                       > Es posible que esto no sea necesario ya que ya esta normalizado\n",
    "        brightness_range=[0.1, 0.7], # specify the range in which to decrease/increase brightness\n",
    "        width_shift_range=0.5,       # shift the width of the image 50%\n",
    "        rotation_range=0,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,        # 180 degree flip horizontally\n",
    "        vertical_flip=True,          # 180 degree flip vertically\n",
    "        validation_split=0.2        # 15% of the data will be used for validation at end of each epoch\n",
    "    )\n",
    "    parametros = {'target_size': (x,y), # CAMBIAR ESTO SEGÚN EL TAMAÑO DE LAS IMAGENES\n",
    "            'batch_size': 64,\n",
    "            'n_classes': 10,\n",
    "            'n_channels': 1,\n",
    "            'subset':'training',\n",
    "            'shuffle': True}\n",
    "    input_entrenamiento = train_generator.flow_from_directory(e_entradas,e_salidas,**parametros)\n",
    "    input_validacion = train_generator.flow_from_directory(v_entradas,v_salidas,**parametros)\n",
    "    return input_entrenamiento,input_validacion\n",
    "entrenamiento, validacion = Augmentation(entrenamiento_entradas,entrenamiento_salidas,validacion_entradas,validacion_salidas,xpixel,ypixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora creamos la arquitectura de la red convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size= (3,3),input_shape=(x,y,3),padding='same',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    # Capas convolucionales\n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    model.add(Conv2D(n_conv2,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # pooling\n",
    "    model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3))) \n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3))) # red fully-connected\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    print(model.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "\n",
    "    # Compilamos\n",
    "    adam = ker.optimizers.Adam(learning_rate= lr)\n",
    "    model.compile(loss=ker.loss.categorical_crossentropy,optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "model = Modelar_red(n_neuronas_conv1,n_neuronas_conv2,n_neuronas_conv3,xpixel,ypixel,l_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar(m,e,v,epo,b): #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(generator = e,validation_data=v,\n",
    "                use_multiprocessing=True,workers=6, # Esta parte es para que se separen 6 threads paralelos gracias a fit_generator\n",
    "                epochs= epo,batch_size = b,verbose=False) \n",
    "        return m\n",
    "model = Entrenar(model,entrenamiento,validacion,epoch,batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo con los datos de test (si hay...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test,s_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,s_test,verbose=False)\n",
    "resultado = Evaluar(model, entrada_test, salida_test) # no existen estas variables todavia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model.predict(x_test) # no existe esta variable todavia\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "- https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/\n",
    "- https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "- https://www.tutorialspoint.com/keras/keras_convolution_neural_network.htm\n",
    "- https://data-flair.training/blogs/keras-convolution-neural-network/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
