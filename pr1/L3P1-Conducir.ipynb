{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output # Limpiar output\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "# La foto es 128x96\n",
    "xpixel = 128\n",
    "ypixel = 96\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 32\n",
    "n_neuronas_conv2 = 64\n",
    "n_neuronas_conv3 = 128\n",
    "l_rate = 0.1\n",
    "epoch = 12 \n",
    "batch = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuestro primer aproach no funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n",
      "Found 22424 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "def crear_data_set_entreno(): # Besitos gonzalo de parte de Ini y Marcos <3\n",
    "    # TECNICAMENTE, CUANDO USAMOS AUGMENTATION SE TIENEN QUE USAR SOLO LOS DATOS AUMENTADOS, AUN ASI, NOSOTROS MEZCLAMOS AMBOS, POR SI ACASO ESO MEJORA LA RED\n",
    "# Creamos un set entero de entrenamiento. A posterior este set lo dividiremos en entrenamiento y validación\n",
    "\n",
    "# Esto es para decir como queremos las nuevas imagenes\n",
    "    augmentation = ImageDataGenerator( # Esto lo vamos a tener que poner todo seguido sin comentar para que no salga plagio !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        rescale=1/255.,              # normalizar                     > Es posible que esto no sea necesario ya que ya esta normalizado\n",
    "        brightness_range=[0.1, 0.7], # luminosidad\n",
    "        width_shift_range=0.5,       # cambiar anhcura 50%\n",
    "        rotation_range=0,            # rotar\n",
    "        shear_range = 0.2,           # idk\n",
    "        zoom_range=0.2,              # zoom\n",
    "        horizontal_flip=False,        # 180º horizontal\n",
    "        vertical_flip=False#,          # 180º vertical\n",
    "        #validation_split=0.2        # usamos el 20% de los datos por epoch\n",
    "        )\n",
    "    # Esto creaa dichas imagenes apartir del directorio que queramos\n",
    "\n",
    "    dataset_entreno_augmentation = augmentation.flow_from_directory(\n",
    "            directory=r\"../Dataset/imgs/train/\",\n",
    "            target_size=(128, 96), #Queremos tener imagenes de la misam resolucion\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=1, # N_img / batch_size = N_nuevas_imagenes\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            seed=42\n",
    "    )\n",
    "\n",
    "\n",
    "    # Ahora creamos el set de entrenamiento con las imagenes originales\n",
    "    dataset_entreno_original = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = r\"../Dataset/imgs/train/\",\n",
    "    seed=123,\n",
    "    image_size=(128, 96),\n",
    "    batch_size=32\n",
    "    )\n",
    "    ### Nos falta añadir las de entreno aparte de las obtenidas por augmentation\n",
    "    # Juntamos los sets de augmentation (las imagenes nuevas) con el set de las originales (las que nos dan)\n",
    "    datasetFinal = dataset_entreno_original, dataset_entreno_augmentation\n",
    "    # Separamos todo en entreno y validacion\n",
    "    entreno, validacion = train_test_split(datasetFinal,test_size = 0.20, shuffle=True) # El entreno es el 80% y el conjunto prueba 20% para el set de augmentation\n",
    "    #entreno_orig_only, validacion_orig_only = train_test_split(dataset_entreno_original,test_size = 0.20, shuffle=True)\n",
    "    entreno_aug_only,validacion_aug_only = train_test_split(dataset_entreno_augmentation,test_size = 0.20, shuffle=True)\n",
    "    #return entreno,validacion,entreno_orig_only,validacion_orig_only,entreno_aug_only,validacion_aug_only \n",
    "    return entreno,validacion,entreno_aug_only,validacion_aug_only \n",
    "\n",
    "entreno,validacion,entreno_aug_only,validacion_aug_only  = crear_data_set_entreno()\n",
    "#entreno,validacion,entreno_orig_only,validacion_orig_only,entreno_aug_only,validacion_aug_only  = crear_data_set_entreno()\n",
    "\n",
    "\n",
    "'''mirar respuestas-> https://stackoverflow.com/questions/57092637/how-to-fit-keras-imagedatagenerator-for-large-data-sets-using-batches'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto coge los datos originales y los divide parece funcionar para model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Esto funciona con fit pero necesito investigar\n",
    "\n",
    "# Mi  teoria de lo que es esto por lo que he leido (OJO NO LO SE REALMENTE) esto crea iteradores que formatean la imagen y la pasan por al model.fit el batch size es en cuanto pedazos pasas\n",
    "# por cadda iteracion como diferencia y hace el split entre validadcion y training no lose pero salia asi en bastantes sitios \n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training     ESTO define como pasas las imagenes\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        validation_split=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator_t = train_datagen.flow_from_directory(                        # Esto creo que crea un iterador en el directorio que sige las intrucciones mencioanda arriba para pasar los\n",
    "                                                                                # datos a model.fit =/ nose es una paranoia\n",
    "        '../Dataset/imgs/train/',  # this is the target directory\n",
    "        color_mode='rgb',\n",
    "        target_size=(128, 96),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset=\"training\")  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "train_generator_v = train_datagen.flow_from_directory(\n",
    "        '../Dataset/imgs/train/',  # this is the target directory\n",
    "        color_mode='rgb',\n",
    "        target_size=(128, 96),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset=\"validation\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Otra Red para no borrar lo ya hecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model = Sequential()\n",
    "\n",
    "    #### Input Layer ####\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
    "                    activation='relu', input_shape=(128, 96, 3)))\n",
    "\n",
    "    #### Convolutional Layers ####\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))  # Pooling\n",
    "    model.add(Dropout(0.2)) # Dropout\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(ker.layers.Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D((4,4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #### Fully-Connected Layer ####\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax')) #len(class_subset) en vez de 10, lo he cambiado pero no estoy seguro\n",
    "\n",
    "    # Compilamos\n",
    "    adam = ker.optimizers.Adam(learning_rate= lr)\n",
    "    model.compile(loss=ker.loss.categorical_crossentropy,optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    model.summary() # a handy way to inspect the architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 96, 32)       896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 96, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 48, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 48, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 48, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 48, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 24, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 24, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 98304)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               50332160  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,578,122\n",
      "Trainable params: 50,578,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def Modelar_red(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size=(3,3),input_shape=(x,y,3),padding='same',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    # Capas convolucionales\n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    # (3,3) es mucho se recomienda unsar 1x1 cuando las img no son mayores de 128x128 la nuestra es 128x96\n",
    "    model.add(Conv2D(n_conv2,(3,3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # pooling\n",
    "    model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same')) \n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected - MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3))) # red fully-connected\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    print(model.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "\n",
    "    # Compilamos\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "model = Modelar_red(n_neuronas_conv1,n_neuronas_conv2,n_neuronas_conv3,xpixel,ypixel,l_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-116:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 745, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 722, in pool_fn\n",
      "    pool = get_pool_class(True)(\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\inigo\\anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n"
     ]
    }
   ],
   "source": [
    "def Entrenar(m,e,v,epo,b): #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(e,\n",
    "        validation_data=v,\n",
    "                use_multiprocessing=True,\n",
    "                workers=6, # Esta parte es para que se separen 6 threads paralelos gracias a fit_generator\n",
    "                epochs= epo,\n",
    "                batch_size = 16,\n",
    "                verbose=False\n",
    "        ) \n",
    "        return m\n",
    "model = Entrenar(model,train_generator_t,train_generator_v,epoch,batch)\n",
    "# DATO CURIOSO, .FIT() TIENE UNA OPCION LLAMADA VALIDATION_DATA=, IGUAL NI ES NECESARIO CREAR UN GRUPO DE VALIDACION A PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo con los datos de test (si hay...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test,s_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,s_test,verbose=False)\n",
    "resultado = Evaluar(model, entrada_test, salida_test) # no existen estas variables todavia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model.predict(x_test) # no existe esta variable todavia\n",
    "print(prediccion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
