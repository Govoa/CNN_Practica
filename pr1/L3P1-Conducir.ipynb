{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Rescaling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "# La foto es 128x96\n",
    "xpixel = 128\n",
    "ypixel = 96\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 64\n",
    "n_neuronas_conv2 = 128\n",
    "n_neuronas_conv3 = 256\n",
    "l_rate = 0.15\n",
    "epoch = 15 \n",
    "batch = 1 # Realmente en 1 esta bien esto es mas para tiempos de ejecucion con grandes cantidades de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto coge los datos originales y los divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meterdatos(batch):\n",
    "    image_size = (xpixel, ypixel)\n",
    "    batch_size = batch\n",
    "\n",
    "    train_generator_t = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=r'../Dataset/imgs/train/',\n",
    "        label_mode = 'categorical',\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        shuffle = True,\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    train_generator_v = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=r'../Dataset/imgs/train/',\n",
    "        label_mode = 'categorical',\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        shuffle = True,\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_generator_t , train_generator_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation no esta implentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meterdatosaug():\n",
    "        train_datagen = ImageDataGenerator( #Aqui se hacen los cambios a las imagenes\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                validation_split = 0.2\n",
    "                )\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                directory=r'../Dataset/imgs/train/',\n",
    "                target_size=(xpixel, ypixel),\n",
    "                batch_size=batch,\n",
    "                class_mode='categorical')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "                directory=r'../Dataset/imgs/train/',\n",
    "                target_size=(xpixel, ypixel),\n",
    "                batch_size=batch,\n",
    "                class_mode='categorical')\n",
    "        return train_generator , validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pintar imagenes dado un tf.keras.preprocessing.image_dataset_from_directory tambien saca el vector de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarimg(t):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in t.take(1):\n",
    "        for i in range(batch):\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            print(labels[i])\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 2 - BUENA DE MOMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_2(n_conv1,n_conv2,n_conv3,x,y,lr,b):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Rescaling(1./255)) # Como no he rescalado nada usamos esta capa para normalizar los datos\n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size=(3,3),input_shape=(b, x, y, 3),padding='same',activation='relu')) \n",
    "    # Capas convolucionales\n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    # (3,3) es mucho se recomienda unsar 1x1 cuando las img no son mayores de 128x128 la nuestra es 128x96\n",
    "    model.add(Conv2D(n_conv2,(3,3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # pooling\n",
    "    model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same')) \n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected - MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu')) # red fully-connected\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    model.build((b, x, y, 3))\n",
    "    print(model.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "    # Compilamos\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 3 - PROBAR\n",
    "\n",
    "https://github.com/fomorians/distracted-drivers-keras/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_3(x,y,lr):\n",
    "\n",
    "    classifier = Sequential()\n",
    "    model.add(Rescaling(1./255)) # Como no he rescalado nada usamos esta capa para normalizar los datos\n",
    "# Step 1 - Convolution\n",
    "\n",
    "    classifier.add(Conv2D(32, (3, 3), input_shape = (xpixel, ypixel, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 2(b) - Add 2nd Convolution Layer making it Deep followed by a Pooling Layer\n",
    "\n",
    "    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "\n",
    "    classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Fully Connected Neural Network\n",
    "\n",
    "# Hidden Layer - Activation Function RELU\n",
    "    classifier.add(Dense(units = 128, activation = 'relu')) \n",
    "# Output Layer - Activation Function Softmax(to clasify multiple classes)\n",
    "    classifier.add(Dense(units = num_clases, activation = 'softmax'))\n",
    "\n",
    "    classifier.build((x, y, 3))\n",
    "    print(classifier.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "    classifier.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    \n",
    "    return classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar(m,e,v,epo,b):\n",
    "        # Para parar segun el criterio de la pr\n",
    "        elcallback = tf.keras.callbacks.EarlyStopping(\n",
    "          monitor=\"val_loss\",\n",
    "          min_delta=0.2,\n",
    "          patience=2,\n",
    "          verbose=0,\n",
    "          mode=\"min\",\n",
    "          baseline=None,\n",
    "          restore_best_weights=False,\n",
    "        )\n",
    "        #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(\n",
    "        e,\n",
    "        validation_data=v,\n",
    "        epochs= epo,\n",
    "        batch_size = b, \n",
    "        verbose=1, #Esto te imprime un progress bar con informacion \n",
    "        shuffle=True,\n",
    "        callbacks = elcallback     \n",
    "        ) \n",
    "        return m\n",
    "# DATO CURIOSO, .FIT() TIENE UNA OPCION LLAMADA VALIDATION_DATA=, IGUAL NI ES NECESARIO CREAR UN GRUPO DE VALIDACION A PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinta modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarmodelo(modelo):\n",
    "    tf.keras.utils.plot_model(\n",
    "        modelo,\n",
    "        to_file='model.png',\n",
    "        show_shapes=False,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir='TB',\n",
    "        expand_nested=False,\n",
    "        dpi=96,\n",
    "        layer_range=None,\n",
    "        show_layer_activations=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarmodelo():\n",
    "    model = ker.models.load_model('path/to/location') # Carga modelos\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardarmodelo():\n",
    "    model.save('ModeloGuardado') # guarda el modelo en la ruta que desees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campo de Maniobras (Esto seria como el main o algo asi jejejee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meterdatos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18556/1963914493.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeterdatos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelar_red_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpixel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypixel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Puedes cambiar la funcion para elegir otro modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meterdatos' is not defined"
     ]
    }
   ],
   "source": [
    "t,v = meterdatos(batch)\n",
    "model = Modelar_red_3(xpixel,ypixel,l_rate) #Puedes cambiar la funcion para elegir otro modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para separar outputs de consola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entrenar(model,t,v,epoch,batch)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
