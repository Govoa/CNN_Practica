{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output # Limpiar output\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "# La foto es 128x96\n",
    "xpixel = 128\n",
    "ypixel = 96\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 64\n",
    "n_neuronas_conv2 = 128\n",
    "n_neuronas_conv3 = 256\n",
    "l_rate = 0.15\n",
    "epoch = 15 \n",
    "batch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto coge los datos originales y los divide parece funcionar para model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto funciona con fit pero necesito investigar\n",
    "\n",
    "# Mi  teoria de lo que es esto por lo que he leido (OJO NO LO SE REALMENTE) esto crea iteradores que formatean la imagen y la pasan por al model.fit el batch size es en cuanto pedazos pasas\n",
    "# por cadda iteracion como diferencia y hace el split entre validadcion y training no lose pero salia asi en bastantes sitios \n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "# this is the augmentation configuration we will use for training     ESTO define como pasas las imagenes puedes modificarlas con parametros yo solo normalizo\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        validation_split=0.2,\n",
    "        )\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator_t = train_datagen.flow_from_directory(                        # Esto creo que crea un iterador en el directorio que sige las intrucciones mencioanda arriba para pasar los                                                                        # datos a model.fit =/ nose es una paranoia\n",
    "        directory=r'../Dataset/imgs/train/',  # this is the target directory\n",
    "        color_mode='rgb',\n",
    "        target_size=(xpixel, ypixel),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset=\"training\")  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "train_generator_v = train_datagen.flow_from_directory(\n",
    "        directory=r'../Dataset/imgs/train/',  # this is the target directory\n",
    "        color_mode='rgb',\n",
    "        target_size=(xpixel, ypixel),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset=\"validation\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismo Concepto pero para test ahora en construccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 \n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=r'../Dataset/imgs/test/',\n",
    "\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(xpixel, ypixel),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 1 - No funciona good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_1(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model = Sequential()\n",
    "\n",
    "    #### Input Layer ####\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
    "                    activation='relu', input_shape=(128, 96, 3)))\n",
    "\n",
    "    #### Convolutional Layers ####\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))  # Pooling\n",
    "    model.add(Dropout(0.2)) # Dropout\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(ker.layers.Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D((4,4)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #### Fully-Connected Layer ####\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax')) #len(class_subset) en vez de 10, lo he cambiado pero no estoy seguro\n",
    "\n",
    "    # Compilamos\n",
    "    adam = ker.optimizers.Adam(learning_rate= lr)\n",
    "    model.compile(loss=ker.loss.categorical_crossentropy,optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    model.summary() # a handy way to inspect the architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 2 - BUENA DE MOMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_2(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size=(1,1),input_shape=(x,y,3),padding='same',activation='relu')) \n",
    "    # Capas convolucionales\n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    # (3,3) es mucho se recomienda unsar 1x1 cuando las img no son mayores de 128x128 la nuestra es 128x96\n",
    "    model.add(Conv2D(n_conv2,(1,1),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # pooling\n",
    "    model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(Conv2D(n_conv3,(1,1),activation='relu',padding='same')) \n",
    "    model.add(Conv2D(n_conv3,(1,1),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected - MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu')) # red fully-connected\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    print(model.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "\n",
    "    # Compilamos\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= lr) # https://keras.io/api/optimizers/adam/ ?\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "model = Modelar_red_2(n_neuronas_conv1,n_neuronas_conv2,n_neuronas_conv3,xpixel,ypixel,l_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED 3 - PROBAR\n",
    "\n",
    "https://github.com/fomorians/distracted-drivers-keras/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red_3(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, 3, border_mode='same', init='he_normal', input_shape=(3, 640, 480)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, 3, 3, border_mode='same', init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, 3, subsample=(2, 2), init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, 3, border_mode='same', init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, 3, subsample=(2, 2), init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, 3, border_mode='same', init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='sigmoid', init='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax', init='he_normal'))\n",
    "    model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar(m,e,v,epo,b):\n",
    " #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(\n",
    "        e,\n",
    "        validation_data=v,\n",
    "        epochs= epo,\n",
    "        batch_size = b, \n",
    "        verbose=1 #Esto te imprime un progress bar con informacion \n",
    "        ) \n",
    "        return m\n",
    "model = Entrenar(model,train_generator_t,train_generator_v,epoch,batch)\n",
    "# DATO CURIOSO, .FIT() TIENE UNA OPCION LLAMADA VALIDATION_DATA=, IGUAL NI ES NECESARIO CREAR UN GRUPO DE VALIDACION A PARTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ker.models.load_model('path/to/location') # Carga modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo2') # guarda el modelo en la ruta que desees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_generator_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test,s_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,s_test,verbose=False)\n",
    "resultado = Evaluar(model, entrada_test, salida_test) # no existen estas variables todavia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model.predict(train_generator_test) # no existe esta variable todavia\n",
    "print(prediccion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
