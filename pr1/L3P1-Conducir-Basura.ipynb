{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as ker\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output # Limpiar output\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las imágenes del entrenamiento leidas y guardadas\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Primer paso es convertir las imagenes en un array y etiquetarlas.\n",
    "    Primero de todo, en el siguiente bucle recorreremos todos los ficheros de entrenamiento, convirtiendo cada imagen en una matriz (normalizada / 255)\n",
    "    Una vez la tenemos normalizada, la añadimos al conjunto de entrenamiento\n",
    "    Como cada imagen esta ya en una carpeta según su clase, guardamos de que carpeta pertenece la imagen y así la etiquetamos en las salidas esperadas\n",
    "\"\"\"\n",
    "\n",
    "entradas_entrenamiento = []\n",
    "salidas_entrenamiento = []\n",
    "\n",
    "with os.scandir('../Dataset/imgs/train') as ficheros: # Iteramos todo el conjunto de entrenamiento\n",
    "    for fichero in ficheros:\n",
    "        path = os.path.join(fichero)\n",
    "        tipo_clase = path.split(\"/\")\n",
    "        clase_img = tipo_clase[4]\n",
    "        print(\"Leyendo imágenes de la carpeta \",clase_img,end=\"\\r\")\n",
    "        with os.scandir(path) as imagenes:\n",
    "            for imagen in imagenes:\n",
    "\n",
    "                salida_individual = []\n",
    "\n",
    "                img_ruta = os.path.join(imagen)\n",
    "                img = Image.open(img_ruta)\n",
    "                img_pixeles = asarray(img) \n",
    "                img_normalizada = img_pixeles / 255 # Normalizamos\n",
    "                entradas_entrenamiento.append(img_normalizada)\n",
    "\n",
    "                clase_img = clase_img[1:]\n",
    "                clase_img = int(clase_img)\n",
    "\n",
    "                # Para cada imagen sacamos un array de la neurona ganadora \n",
    "                for x in range(10):\n",
    "                    if x == clase_img:\n",
    "                        salida_individual.append(1)\n",
    "                    else:\n",
    "                        salida_individual.append(0)\n",
    "\n",
    "                salidas_entrenamiento.append(salida_individual)\n",
    "\n",
    "                break # Comentar para ejecución\n",
    "print(\"Todas las imágenes del entrenamiento leidas y guardadas\")\n",
    "\n",
    "# Ahora hacemos shuffle y dividimos en entreno y validacion\n",
    "\n",
    "# Shuffle de ambos a la vez para que las posiciones concuerden con las salidas\n",
    "shuffle = list(zip(entradas_entrenamiento, salidas_entrenamiento))\n",
    "random.shuffle(shuffle)\n",
    "entradas_entrenamiento, salidas_entrenamiento = zip(*shuffle)\n",
    "\n",
    "# División\n",
    "entrenamiento_entradas, validacion_entradas = train_test_split(entradas_entrenamiento, test_size = 0.20, shuffle=False)\n",
    "entrenamiento_salidas, validacion_salidas = train_test_split(salidas_entrenamiento, test_size = 0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar\n",
    "num_clases = 10\n",
    "# La foto es 640x480\n",
    "xpixel = len(img_pixeles[1])\n",
    "ypixel = len(img_pixeles[0])\n",
    "\n",
    "# Tocar\n",
    "n_neuronas_conv1 = 32\n",
    "n_neuronas_conv2 = 32\n",
    "n_neuronas_conv3 = 32\n",
    "l_rate = 0.1\n",
    "epoch = 12 \n",
    "batch = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero realizamos la aumentación y creación de nuevos imputs a partir de las imagenes que tenemos (Augmentation)\n",
    "Lo realizamos con ImageDataGenerator de keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flow() got an unexpected keyword argument 'n_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=22'>23</a>\u001b[0m     input_validacion \u001b[39m=\u001b[39m train_generator\u001b[39m.\u001b[39mflow(v_entradas,v_salidas,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparametros)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m input_entrenamiento,input_validacion\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=24'>25</a>\u001b[0m entrenamiento, validacion \u001b[39m=\u001b[39m Augmentation(entrenamiento_entradas,entrenamiento_salidas,validacion_entradas,validacion_salidas,xpixel,ypixel)\n",
      "\u001b[1;32m/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb Cell 11'\u001b[0m in \u001b[0;36mAugmentation\u001b[0;34m(e_entradas, e_salidas, v_entradas, v_salidas, x, y)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=2'>3</a>\u001b[0m train_generator \u001b[39m=\u001b[39m ImageDataGenerator( \u001b[39m# Esto lo vamos a tener que poner todo seguido sin comentar para que no salga plagio !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=3'>4</a>\u001b[0m     rescale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255.\u001b[39m,              \u001b[39m# normalizar                     > Es posible que esto no sea necesario ya que ya esta normalizado\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=4'>5</a>\u001b[0m     brightness_range\u001b[39m=\u001b[39m[\u001b[39m0.1\u001b[39m, \u001b[39m0.7\u001b[39m], \u001b[39m# luminosidad\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=11'>12</a>\u001b[0m     validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m        \u001b[39m# usamos el 20% de los datos por epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=14'>15</a>\u001b[0m parametros \u001b[39m=\u001b[39m { \u001b[39m# CAMBIAR ESTO SEGÚN EL TAMAÑO DE LAS IMAGENES\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=15'>16</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m64\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=16'>17</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mn_classes\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=17'>18</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mn_channels\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=18'>19</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msubset\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=19'>20</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=21'>22</a>\u001b[0m input_entrenamiento \u001b[39m=\u001b[39m train_generator\u001b[39m.\u001b[39;49mflow(e_entradas,e_salidas,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparametros)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=22'>23</a>\u001b[0m input_validacion \u001b[39m=\u001b[39m train_generator\u001b[39m.\u001b[39mflow(v_entradas,v_salidas,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparametros)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonzalo/Desktop/IAII/PRACTICA3/pr1/L3P1-Conducir.ipynb#ch0000010?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m input_entrenamiento,input_validacion\n",
      "\u001b[0;31mTypeError\u001b[0m: flow() got an unexpected keyword argument 'n_classes'"
     ]
    }
   ],
   "source": [
    "def Augmentation(e_entradas,e_salidas,v_entradas,v_salidas,x,y):\n",
    "    # La aumgentation es la modificación de las fotos para que sea funcional\n",
    "    train_generator = ImageDataGenerator( # Esto lo vamos a tener que poner todo seguido sin comentar para que no salga plagio !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        rescale=1/255.,              # normalizar                     > Es posible que esto no sea necesario ya que ya esta normalizado\n",
    "        brightness_range=[0.1, 0.7], # luminosidad\n",
    "        width_shift_range=0.5,       # cambiar anhcura 50%\n",
    "        rotation_range=0,            # rotar\n",
    "        shear_range = 0.2,           # idk\n",
    "        zoom_range=0.2,              # zoom\n",
    "        horizontal_flip=True,        # 180º horizontal\n",
    "        vertical_flip=True,          # 180º vertical\n",
    "        validation_split=0.2        # usamos el 20% de los datos por epoch\n",
    "    )\n",
    "    \n",
    "    parametros = {'target_size': (x,y), # CAMBIAR ESTO SEGÚN EL TAMAÑO DE LAS IMAGENES\n",
    "            'batch_size': 64,\n",
    "            'n_classes': 10,\n",
    "            'n_channels': 3,\n",
    "            'subset':'training',\n",
    "            'shuffle': True}\n",
    "            \n",
    "    input_entrenamiento = train_generator.flow(e_entradas,e_salidas,**parametros)\n",
    "    input_validacion = train_generator.flow(v_entradas,v_salidas,**parametros)\n",
    "    return input_entrenamiento,input_validacion\n",
    "entrenamiento, validacion = Augmentation(entrenamiento_entradas,entrenamiento_salidas,validacion_entradas,validacion_salidas,xpixel,ypixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora creamos la arquitectura de la red convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelar_red(n_conv1,n_conv2,n_conv3,x,y,lr):\n",
    "    model=Sequential()\n",
    "    # Capa input\n",
    "    model.add(Conv2D(filters= n_conv1, kernel_size= (3,3),input_shape=(x,y,3),padding='same',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    # Capas convolucionales\n",
    "    #   >este bloque se puede seguir añadiendo, quiza con menos neuronas, o menos capas convolucionales, pongo dos por dar un ejemplo nada mas\n",
    "    model.add(Conv2D(n_conv2,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # pooling\n",
    "    model.add(Dropout(0.2)) # dropout\n",
    "\n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3))) \n",
    "    model.add(Conv2D(n_conv3,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    # Capa fully-connected - MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3))) # red fully-connected\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_clases, activation='softmax')) # capa de salida(softmaxx) \n",
    "\n",
    "    print(model.summary()) # con esto inspeccionamos el modelo, muy comodo\n",
    "\n",
    "    # Compilamos\n",
    "    adam = ker.optimizers.Adam(learning_rate= lr)\n",
    "    model.compile(loss=ker.loss.categorical_crossentropy,optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "model = Modelar_red(n_neuronas_conv1,n_neuronas_conv2,n_neuronas_conv3,xpixel,ypixel,l_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora realizamos el fit para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar(m,e,v,epo,b): #(model,entrenamiento,validacion, epoch,batch)\n",
    "        m.fit(generator = e,validation_data=v,\n",
    "                use_multiprocessing=True,workers=6, # Esta parte es para que se separen 6 threads paralelos gracias a fit_generator\n",
    "                epochs= epo,batch_size = b,verbose=False) \n",
    "        return m\n",
    "model = Entrenar(model,entrenamiento,validacion,epoch,batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo con los datos de test (si hay...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluar(m,e_test,s_test): # model,entrada_test,salida_test\n",
    "    return m.evaluate(e_test,s_test,verbose=False)\n",
    "resultado = Evaluar(model, entrada_test, salida_test) # no existen estas variables todavia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model.predict(x_test) # no existe esta variable todavia\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "- https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/\n",
    "- https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "- https://www.tutorialspoint.com/keras/keras_convolution_neural_network.htm\n",
    "- https://data-flair.training/blogs/keras-convolution-neural-network/\n",
    "- https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae011bd53887c3dab0246b667a51a9d69f3606ce064e4af6110c47693a17202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
